{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e62b89f-4278-4f1d-980b-654bd763106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f351806c-8a0d-4352-ab86-708cec97380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.27.1-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
      "  Downloading rapidfuzz-3.12.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.27.1-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6b445c-6648-478b-9f45-44140a044e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "Hot100: 5200 rows\n",
      "Radio: 2600 rows\n",
      "Streaming: 2600 rows\n",
      "Sales: 1300 rows\n",
      "Apple: 5200 rows\n",
      "Spotify: 10400 rows\n",
      "\n",
      "Renaming Hot100 columns...\n",
      "\n",
      "Creating normalized matching columns...\n",
      "\n",
      "Initializing platform columns...\n",
      "\n",
      "Matching songs and copying data...\n",
      "Processing RADIO data:\n",
      "  Week 1: Matched 38 of 100 songs\n",
      "  Week 2: Matched 43 of 100 songs\n",
      "  Week 3: Matched 46 of 100 songs\n",
      "  Week 4: Matched 43 of 100 songs\n",
      "  Week 5: Matched 47 of 100 songs\n",
      "  Week 6: Matched 47 of 100 songs\n",
      "  Week 7: Matched 46 of 100 songs\n",
      "  Week 8: Matched 43 of 100 songs\n",
      "  Week 9: Matched 46 of 100 songs\n",
      "  Week 10: Matched 45 of 100 songs\n",
      "  Week 11: Matched 46 of 100 songs\n",
      "  Week 12: Matched 46 of 100 songs\n",
      "  Week 13: Matched 44 of 100 songs\n",
      "  Week 14: Matched 40 of 100 songs\n",
      "  Week 15: Matched 37 of 100 songs\n",
      "  Week 16: Matched 40 of 100 songs\n",
      "  Week 17: Matched 40 of 100 songs\n",
      "  Week 18: Matched 36 of 100 songs\n",
      "  Week 19: Matched 36 of 100 songs\n",
      "  Week 20: Matched 37 of 100 songs\n",
      "  Week 21: Matched 36 of 100 songs\n",
      "  Week 22: Matched 39 of 100 songs\n",
      "  Week 23: Matched 40 of 100 songs\n",
      "  Week 24: Matched 42 of 100 songs\n",
      "  Week 25: Matched 40 of 100 songs\n",
      "  Week 26: Matched 41 of 100 songs\n",
      "  Week 27: Matched 39 of 100 songs\n",
      "  Week 28: Matched 40 of 100 songs\n",
      "  Week 29: Matched 37 of 100 songs\n",
      "  Week 30: Matched 37 of 100 songs\n",
      "  Week 31: Matched 40 of 100 songs\n",
      "  Week 32: Matched 38 of 100 songs\n",
      "  Week 33: Matched 39 of 100 songs\n",
      "  Week 34: Matched 42 of 100 songs\n",
      "  Week 35: Matched 40 of 100 songs\n",
      "  Week 36: Matched 41 of 100 songs\n",
      "  Week 37: Matched 43 of 100 songs\n",
      "  Week 38: Matched 42 of 100 songs\n",
      "  Week 39: Matched 44 of 100 songs\n",
      "  Week 40: Matched 40 of 100 songs\n",
      "  Week 41: Matched 44 of 100 songs\n",
      "  Week 42: Matched 43 of 100 songs\n",
      "  Week 43: Matched 40 of 100 songs\n",
      "  Week 44: Matched 40 of 100 songs\n",
      "  Week 45: Matched 40 of 100 songs\n",
      "  Week 46: Matched 40 of 100 songs\n",
      "  Week 47: Matched 42 of 100 songs\n",
      "  Week 48: Matched 40 of 100 songs\n",
      "  Week 49: Matched 39 of 100 songs\n",
      "  Week 50: Matched 37 of 100 songs\n",
      "  Week 51: Matched 36 of 100 songs\n",
      "  Week 52: Matched 37 of 100 songs\n",
      "RADIO data verification: 2124 songs with non-zero rank\n",
      "\n",
      "Processing STREAMING data:\n",
      "  Week 1: Matched 45 of 100 songs\n",
      "  Week 2: Matched 43 of 100 songs\n",
      "  Week 3: Matched 42 of 100 songs\n",
      "  Week 4: Matched 48 of 100 songs\n",
      "  Week 5: Matched 46 of 100 songs\n",
      "  Week 6: Matched 43 of 100 songs\n",
      "  Week 7: Matched 43 of 100 songs\n",
      "  Week 8: Matched 46 of 100 songs\n",
      "  Week 9: Matched 44 of 100 songs\n",
      "  Week 10: Matched 42 of 100 songs\n",
      "  Week 11: Matched 42 of 100 songs\n",
      "  Week 12: Matched 45 of 100 songs\n",
      "  Week 13: Matched 45 of 100 songs\n",
      "  Week 14: Matched 47 of 100 songs\n",
      "  Week 15: Matched 47 of 100 songs\n",
      "  Week 16: Matched 46 of 100 songs\n",
      "  Week 17: Matched 45 of 100 songs\n",
      "  Week 18: Matched 50 of 100 songs\n",
      "  Week 19: Matched 45 of 100 songs\n",
      "  Week 20: Matched 44 of 100 songs\n",
      "  Week 21: Matched 43 of 100 songs\n",
      "  Week 22: Matched 43 of 100 songs\n",
      "  Week 23: Matched 43 of 100 songs\n",
      "  Week 24: Matched 42 of 100 songs\n",
      "  Week 25: Matched 42 of 100 songs\n",
      "  Week 26: Matched 42 of 100 songs\n",
      "  Week 27: Matched 42 of 100 songs\n",
      "  Week 28: Matched 41 of 100 songs\n",
      "  Week 29: Matched 44 of 100 songs\n",
      "  Week 30: Matched 46 of 100 songs\n",
      "  Week 31: Matched 42 of 100 songs\n",
      "  Week 32: Matched 43 of 100 songs\n",
      "  Week 33: Matched 45 of 100 songs\n",
      "  Week 34: Matched 43 of 100 songs\n",
      "  Week 35: Matched 46 of 100 songs\n",
      "  Week 36: Matched 46 of 100 songs\n",
      "  Week 37: Matched 46 of 100 songs\n",
      "  Week 38: Matched 44 of 100 songs\n",
      "  Week 39: Matched 46 of 100 songs\n",
      "  Week 40: Matched 46 of 100 songs\n",
      "  Week 41: Matched 43 of 100 songs\n",
      "  Week 42: Matched 40 of 100 songs\n",
      "  Week 43: Matched 44 of 100 songs\n",
      "  Week 44: Matched 39 of 100 songs\n",
      "  Week 45: Matched 47 of 100 songs\n",
      "  Week 46: Matched 46 of 100 songs\n",
      "  Week 47: Matched 42 of 100 songs\n",
      "  Week 48: Matched 43 of 100 songs\n",
      "  Week 49: Matched 49 of 100 songs\n",
      "  Week 50: Matched 48 of 100 songs\n",
      "  Week 51: Matched 48 of 100 songs\n",
      "  Week 52: Matched 45 of 100 songs\n",
      "STREAMING data verification: 2307 songs with non-zero rank\n",
      "\n",
      "Processing SALES data:\n",
      "  Week 1: Matched 16 of 100 songs\n",
      "  Week 2: Matched 23 of 100 songs\n",
      "  Week 3: Matched 19 of 100 songs\n",
      "  Week 4: Matched 21 of 100 songs\n",
      "  Week 5: Matched 20 of 100 songs\n",
      "  Week 6: Matched 21 of 100 songs\n",
      "  Week 7: Matched 11 of 100 songs\n",
      "  Week 8: Matched 13 of 100 songs\n",
      "  Week 9: Matched 18 of 100 songs\n",
      "  Week 10: Matched 19 of 100 songs\n",
      "  Week 11: Matched 20 of 100 songs\n",
      "  Week 12: Matched 15 of 100 songs\n",
      "  Week 13: Matched 15 of 100 songs\n",
      "  Week 14: Matched 19 of 100 songs\n",
      "  Week 15: Matched 16 of 100 songs\n",
      "  Week 16: Matched 15 of 100 songs\n",
      "  Week 17: Matched 14 of 100 songs\n",
      "  Week 18: Matched 24 of 100 songs\n",
      "  Week 19: Matched 14 of 100 songs\n",
      "  Week 20: Matched 17 of 100 songs\n",
      "  Week 21: Matched 17 of 100 songs\n",
      "  Week 22: Matched 19 of 100 songs\n",
      "  Week 23: Matched 14 of 100 songs\n",
      "  Week 24: Matched 22 of 100 songs\n",
      "  Week 25: Matched 20 of 100 songs\n",
      "  Week 26: Matched 23 of 100 songs\n",
      "  Week 27: Matched 22 of 100 songs\n",
      "  Week 28: Matched 24 of 100 songs\n",
      "  Week 29: Matched 25 of 100 songs\n",
      "  Week 30: Matched 20 of 100 songs\n",
      "  Week 31: Matched 20 of 100 songs\n",
      "  Week 32: Matched 24 of 100 songs\n",
      "  Week 33: Matched 23 of 100 songs\n",
      "  Week 34: Matched 23 of 100 songs\n",
      "  Week 35: Matched 21 of 100 songs\n",
      "  Week 36: Matched 18 of 100 songs\n",
      "  Week 37: Matched 23 of 100 songs\n",
      "  Week 38: Matched 22 of 100 songs\n",
      "  Week 39: Matched 20 of 100 songs\n",
      "  Week 40: Matched 18 of 100 songs\n",
      "  Week 41: Matched 21 of 100 songs\n",
      "  Week 42: Matched 20 of 100 songs\n",
      "  Week 43: Matched 17 of 100 songs\n",
      "  Week 44: Matched 19 of 100 songs\n",
      "  Week 45: Matched 20 of 100 songs\n",
      "  Week 46: Matched 19 of 100 songs\n",
      "  Week 47: Matched 20 of 100 songs\n",
      "  Week 48: Matched 18 of 100 songs\n",
      "  Week 49: Matched 19 of 100 songs\n",
      "  Week 50: Matched 19 of 100 songs\n",
      "  Week 51: Matched 19 of 100 songs\n",
      "  Week 52: Matched 19 of 100 songs\n",
      "SALES data verification: 998 songs with non-zero rank\n",
      "\n",
      "Processing APPLE data:\n",
      "  Week 1: Matched 47 of 100 songs\n",
      "  Week 2: Matched 31 of 100 songs\n",
      "  Week 3: Matched 44 of 100 songs\n",
      "  Week 4: Matched 52 of 100 songs\n",
      "  Week 5: Matched 49 of 100 songs\n",
      "  Week 6: Matched 46 of 100 songs\n",
      "  Week 7: Matched 43 of 100 songs\n",
      "  Week 8: Matched 36 of 100 songs\n",
      "  Week 9: Matched 36 of 100 songs\n",
      "  Week 10: Matched 37 of 100 songs\n",
      "  Week 11: Matched 37 of 100 songs\n",
      "  Week 12: Matched 45 of 100 songs\n",
      "  Week 13: Matched 49 of 100 songs\n",
      "  Week 14: Matched 51 of 100 songs\n",
      "  Week 15: Matched 60 of 100 songs\n",
      "  Week 16: Matched 48 of 100 songs\n",
      "  Week 17: Matched 41 of 100 songs\n",
      "  Week 18: Matched 56 of 100 songs\n",
      "  Week 19: Matched 58 of 100 songs\n",
      "  Week 20: Matched 56 of 100 songs\n",
      "  Week 21: Matched 50 of 100 songs\n",
      "  Week 22: Matched 55 of 100 songs\n",
      "  Week 23: Matched 55 of 100 songs\n",
      "  Week 24: Matched 52 of 100 songs\n",
      "  Week 25: Matched 52 of 100 songs\n",
      "  Week 26: Matched 54 of 100 songs\n",
      "  Week 27: Matched 52 of 100 songs\n",
      "  Week 28: Matched 49 of 100 songs\n",
      "  Week 29: Matched 58 of 100 songs\n",
      "  Week 30: Matched 60 of 100 songs\n",
      "  Week 31: Matched 48 of 100 songs\n",
      "  Week 32: Matched 51 of 100 songs\n",
      "  Week 33: Matched 52 of 100 songs\n",
      "  Week 34: Matched 48 of 100 songs\n",
      "  Week 35: Matched 56 of 100 songs\n",
      "  Week 36: Matched 49 of 100 songs\n",
      "  Week 37: Matched 51 of 100 songs\n",
      "  Week 38: Matched 49 of 100 songs\n",
      "  Week 39: Matched 50 of 100 songs\n",
      "  Week 40: Matched 60 of 100 songs\n",
      "  Week 41: Matched 52 of 100 songs\n",
      "  Week 42: Matched 49 of 100 songs\n",
      "  Week 43: Matched 57 of 100 songs\n",
      "  Week 44: Matched 46 of 100 songs\n",
      "  Week 45: Matched 46 of 100 songs\n",
      "  Week 46: Matched 52 of 100 songs\n",
      "  Week 47: Matched 52 of 100 songs\n",
      "  Week 48: Matched 55 of 100 songs\n",
      "  Week 49: Matched 58 of 100 songs\n",
      "  Week 50: Matched 64 of 100 songs\n",
      "  Week 51: Matched 60 of 100 songs\n",
      "  Week 52: Matched 64 of 100 songs\n",
      "APPLE data verification: 2628 songs with non-zero rank\n",
      "\n",
      "Processing SPOTIFY data:\n",
      "  Week 1: Matched 61 of 100 songs\n",
      "  Week 2: Matched 69 of 100 songs\n",
      "  Week 3: Matched 65 of 100 songs\n",
      "  Week 4: Matched 69 of 100 songs\n",
      "  Week 5: Matched 69 of 100 songs\n",
      "  Week 6: Matched 69 of 100 songs\n",
      "  Week 7: Matched 72 of 100 songs\n",
      "  Week 8: Matched 55 of 100 songs\n",
      "  Week 9: Matched 63 of 100 songs\n",
      "  Week 10: Matched 65 of 100 songs\n",
      "  Week 11: Matched 65 of 100 songs\n",
      "  Week 12: Matched 72 of 100 songs\n",
      "  Week 13: Matched 72 of 100 songs\n",
      "  Week 14: Matched 67 of 100 songs\n",
      "  Week 15: Matched 78 of 100 songs\n",
      "  Week 16: Matched 76 of 100 songs\n",
      "  Week 17: Matched 62 of 100 songs\n",
      "  Week 18: Matched 76 of 100 songs\n",
      "  Week 19: Matched 79 of 100 songs\n",
      "  Week 20: Matched 78 of 100 songs\n",
      "  Week 21: Matched 74 of 100 songs\n",
      "  Week 22: Matched 78 of 100 songs\n",
      "  Week 23: Matched 78 of 100 songs\n",
      "  Week 24: Matched 78 of 100 songs\n",
      "  Week 25: Matched 76 of 100 songs\n",
      "  Week 26: Matched 77 of 100 songs\n",
      "  Week 27: Matched 80 of 100 songs\n",
      "  Week 28: Matched 75 of 100 songs\n",
      "  Week 29: Matched 82 of 100 songs\n",
      "  Week 30: Matched 80 of 100 songs\n",
      "  Week 31: Matched 77 of 100 songs\n",
      "  Week 32: Matched 73 of 100 songs\n",
      "  Week 33: Matched 73 of 100 songs\n",
      "  Week 34: Matched 67 of 100 songs\n",
      "  Week 35: Matched 80 of 100 songs\n",
      "  Week 36: Matched 76 of 100 songs\n",
      "  Week 37: Matched 76 of 100 songs\n",
      "  Week 38: Matched 78 of 100 songs\n",
      "  Week 39: Matched 73 of 100 songs\n",
      "  Week 40: Matched 69 of 100 songs\n",
      "  Week 41: Matched 70 of 100 songs\n",
      "  Week 42: Matched 62 of 100 songs\n",
      "  Week 43: Matched 55 of 100 songs\n",
      "  Week 44: Matched 61 of 100 songs\n",
      "  Week 45: Matched 66 of 100 songs\n",
      "  Week 46: Matched 64 of 100 songs\n",
      "  Week 47: Matched 60 of 100 songs\n",
      "  Week 48: Matched 63 of 100 songs\n",
      "  Week 49: Matched 69 of 100 songs\n",
      "  Week 50: Matched 73 of 100 songs\n",
      "  Week 51: Matched 69 of 100 songs\n",
      "  Week 52: Matched 66 of 100 songs\n",
      "SPOTIFY data verification: 3680 songs with non-zero rank\n",
      "\n",
      "FINAL VERIFICATION:\n",
      "Total rows: 5200\n",
      "Hot100 songs: 5200\n",
      "Radio songs: 2124\n",
      "Streaming songs: 2307\n",
      "Sales songs: 998\n",
      "Apple songs: 2628\n",
      "Spotify songs: 3680\n",
      "\n",
      "Performing strategic label filling...\n",
      "Step 1: Filling labels based on temporal data...\n",
      "Filled 500 labels using temporal matching\n",
      "Step 2: Filling labels based on artist's common label...\n",
      "Filled 440 labels using artist's common label\n",
      "Filled 580 remaining empty labels with 'Unknown'\n",
      "Songs with known labels: 4620 of 5200\n",
      "\n",
      "Adding derived features...\n",
      "Calculating platform changes...\n",
      "  Calculating hot100_change\n",
      "  Calculating radio_change\n",
      "  Calculating streaming_change\n",
      "  Calculating sales_change\n",
      "  Calculating apple_change\n",
      "  Calculating spotify_change\n",
      "Calculating available platforms...\n",
      "Determining best platform...\n",
      "Calculating platform momentum...\n",
      "\n",
      "Cleaning data...\n",
      "\n",
      "Adding advanced features...\n",
      "\n",
      "Rearranging columns...\n",
      "\n",
      "Saving final dataset...\n",
      "Final dataset saved successfully!\n",
      "\n",
      "FINAL VERIFICATION OF ENHANCED DATASET:\n",
      "Total rows: 5200\n",
      "Hot100 songs: 5200\n",
      "Radio songs: 2124\n",
      "Streaming songs: 2307\n",
      "Sales songs: 998\n",
      "Apple songs: 2628\n",
      "Spotify songs: 3680\n",
      "Songs with known labels: 4620 of 5200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Path to files\n",
    "base_path = \"C:/Users/w196283/Downloads/cleaned/\"\n",
    "files = {\n",
    "    'hot100': base_path + \"hot100_transformed.csv\",\n",
    "    'radio': base_path + \"radio_transformed.csv\",\n",
    "    'streaming': base_path + \"streaming_transformed.csv\",\n",
    "    'sales': base_path + \"sales_transformed.csv\",\n",
    "    'apple': base_path + \"apple_music_transformed.csv\",\n",
    "    'spotify': base_path + \"spotify_transformed.csv\"\n",
    "}\n",
    "\n",
    "# Load all data files\n",
    "hot100_df = pd.read_csv(files['hot100'])\n",
    "radio_df = pd.read_csv(files['radio'])\n",
    "streaming_df = pd.read_csv(files['streaming'])\n",
    "sales_df = pd.read_csv(files['sales'])\n",
    "apple_df = pd.read_csv(files['apple'])\n",
    "spotify_df = pd.read_csv(files['spotify'])\n",
    "\n",
    "print(\"Data loaded successfully\")\n",
    "print(f\"Hot100: {len(hot100_df)} rows\")\n",
    "print(f\"Radio: {len(radio_df)} rows\")\n",
    "print(f\"Streaming: {len(streaming_df)} rows\")\n",
    "print(f\"Sales: {len(sales_df)} rows\")\n",
    "print(f\"Apple: {len(apple_df)} rows\")\n",
    "print(f\"Spotify: {len(spotify_df)} rows\")\n",
    "\n",
    "# Improved function to clean text for matching\n",
    "def clean_for_matching(text):\n",
    "    \"\"\"Normalize text for fuzzy matching\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # Replace various forms of \"featuring\"\n",
    "    text = re.sub(r'(\\sfeat\\.|\\sfeaturing|\\sft\\.|\\swith|\\sand|\\s&|\\svs\\.|\\svs\\s).*', '', text)\n",
    "    \n",
    "    # Remove text in parentheses and brackets\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'\\[[^\\]]*\\]', '', text)\n",
    "    \n",
    "    # Replace punctuation and special characters with spaces\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Remove specific words that might cause confusion\n",
    "    text = re.sub(r'\\b(the|a|an)\\b', '', text)\n",
    "    \n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Create a fresh unified dataset starting with Hot100\n",
    "unified = hot100_df.copy()\n",
    "\n",
    "# Based on the data you showed, here are the actual column mappings:\n",
    "print(\"\\nRenaming Hot100 columns...\")\n",
    "unified = unified.rename(columns={\n",
    "    'rank': 'hot100_rank',\n",
    "    'bb_last_week': 'hot100_last_week',\n",
    "    'bb_peak': 'hot100_peak',\n",
    "    'bb_woc': 'hot100_woc'\n",
    "})\n",
    "\n",
    "# Ensure label column exists\n",
    "if 'label' not in unified.columns:\n",
    "    unified['label'] = ''\n",
    "\n",
    "# Create normalized columns for matching\n",
    "print(\"\\nCreating normalized matching columns...\")\n",
    "unified['track_clean'] = unified['track'].apply(clean_for_matching)\n",
    "unified['artist_clean'] = unified['artist'].apply(clean_for_matching)\n",
    "\n",
    "radio_df['track_clean'] = radio_df['track'].apply(clean_for_matching)\n",
    "radio_df['artist_clean'] = radio_df['artist'].apply(clean_for_matching)\n",
    "\n",
    "streaming_df['track_clean'] = streaming_df['track'].apply(clean_for_matching)\n",
    "streaming_df['artist_clean'] = streaming_df['artist'].apply(clean_for_matching)\n",
    "\n",
    "sales_df['track_clean'] = sales_df['track'].apply(clean_for_matching)\n",
    "sales_df['artist_clean'] = sales_df['artist'].apply(clean_for_matching)\n",
    "\n",
    "apple_df['track_clean'] = apple_df['track'].apply(clean_for_matching)\n",
    "apple_df['artist_clean'] = apple_df['artist'].apply(clean_for_matching)\n",
    "\n",
    "spotify_df['track_clean'] = spotify_df['track'].apply(clean_for_matching)\n",
    "spotify_df['artist_clean'] = spotify_df['artist'].apply(clean_for_matching)\n",
    "\n",
    "# Initialize all platform columns with zeros\n",
    "print(\"\\nInitializing platform columns...\")\n",
    "# Radio columns\n",
    "unified['radio_rank'] = 0\n",
    "unified['radio_last_week'] = 0\n",
    "unified['radio_peak'] = 0\n",
    "unified['radio_woc'] = 0\n",
    "unified['radio_change'] = 0.0\n",
    "\n",
    "# Streaming columns\n",
    "unified['streaming_rank'] = 0\n",
    "unified['streaming_last_week'] = 0\n",
    "unified['streaming_peak'] = 0\n",
    "unified['streaming_woc'] = 0\n",
    "unified['streaming_change'] = 0.0\n",
    "\n",
    "# Sales columns\n",
    "unified['sales_rank'] = 0\n",
    "unified['sales_last_week'] = 0\n",
    "unified['sales_peak'] = 0\n",
    "unified['sales_woc'] = 0\n",
    "unified['sales_change'] = 0.0\n",
    "\n",
    "# Apple columns\n",
    "unified['apple_rank'] = 0\n",
    "unified['apple_last_week'] = 0\n",
    "unified['apple_peak'] = 0\n",
    "unified['apple_woc'] = 0\n",
    "unified['apple_change'] = 0.0\n",
    "\n",
    "# Spotify columns\n",
    "unified['spotify_rank'] = 0\n",
    "unified['spotify_last_week'] = 0\n",
    "unified['spotify_peak'] = 0\n",
    "unified['spotify_woc'] = 0\n",
    "unified['spotify_change'] = 0.0\n",
    "unified['spotify_streams'] = 0\n",
    "\n",
    "# For Hot100, add change column\n",
    "unified['hot100_change'] = 0.0\n",
    "\n",
    "# Function to find matches with fallback to fuzzy matching\n",
    "def find_match(hot_row, platform_week_df, threshold=85):\n",
    "    # Try direct match first\n",
    "    match = platform_week_df[(platform_week_df['track_clean'] == hot_row['track_clean']) & \n",
    "                           (platform_week_df['artist_clean'] == hot_row['artist_clean'])]\n",
    "    \n",
    "    if not match.empty:\n",
    "        return match.iloc[0]\n",
    "    \n",
    "    # Try matching just by track name if artist is the same\n",
    "    match = platform_week_df[(platform_week_df['artist_clean'] == hot_row['artist_clean'])]\n",
    "    if not match.empty:\n",
    "        # Find best track match\n",
    "        for _, row in match.iterrows():\n",
    "            ratio = fuzz.token_sort_ratio(row['track_clean'], hot_row['track_clean'])\n",
    "            if ratio >= threshold:\n",
    "                return row\n",
    "    \n",
    "    # Try matching by track name with fuzzy artist matching\n",
    "    match = platform_week_df[platform_week_df['track_clean'] == hot_row['track_clean']]\n",
    "    if not match.empty:\n",
    "        # Find best artist match\n",
    "        for _, row in match.iterrows():\n",
    "            ratio = fuzz.token_sort_ratio(row['artist_clean'], hot_row['artist_clean'])\n",
    "            if ratio >= threshold:\n",
    "                return row\n",
    "    \n",
    "    # If still no match, try fuzzy matching on both track and artist\n",
    "    for _, row in platform_week_df.iterrows():\n",
    "        track_ratio = fuzz.token_sort_ratio(row['track_clean'], hot_row['track_clean'])\n",
    "        artist_ratio = fuzz.token_sort_ratio(row['artist_clean'], hot_row['artist_clean'])\n",
    "        \n",
    "        # Combined score gives more weight to track name\n",
    "        combined_ratio = (track_ratio * 0.7) + (artist_ratio * 0.3)\n",
    "        \n",
    "        if combined_ratio >= threshold:\n",
    "            return row\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Match and copy data by week\n",
    "print(\"\\nMatching songs and copying data...\")\n",
    "\n",
    "# 1. Radio data\n",
    "print(\"Processing RADIO data:\")\n",
    "for week in unified['week'].unique():\n",
    "    unified_week = unified[unified['week'] == week]\n",
    "    radio_week = radio_df[radio_df['week'] == week]\n",
    "    \n",
    "    if radio_week.empty:\n",
    "        print(f\"  Week {week}: No radio data\")\n",
    "        continue\n",
    "    \n",
    "    matches = 0\n",
    "    for idx, hot_row in unified_week.iterrows():\n",
    "        match_row = find_match(hot_row, radio_week)\n",
    "        \n",
    "        if match_row is not None:\n",
    "            # Copy rank\n",
    "            unified.loc[idx, 'radio_rank'] = match_row['rank']\n",
    "            \n",
    "            # Copy other metrics\n",
    "            unified.loc[idx, 'radio_last_week'] = match_row['radio_last_week']\n",
    "            unified.loc[idx, 'radio_peak'] = match_row['radio_peak']\n",
    "            unified.loc[idx, 'radio_woc'] = match_row['radio_woc']\n",
    "            \n",
    "            # Copy label if available\n",
    "            if 'label' in match_row and pd.notnull(match_row['label']) and match_row['label'] != '':\n",
    "                if pd.isnull(unified.loc[idx, 'label']) or unified.loc[idx, 'label'] == '':\n",
    "                    unified.loc[idx, 'label'] = match_row['label']\n",
    "            \n",
    "            matches += 1\n",
    "    \n",
    "    print(f\"  Week {week}: Matched {matches} of {len(unified_week)} songs\")\n",
    "\n",
    "# Print verification\n",
    "radio_matched = (unified['radio_rank'] > 0).sum()\n",
    "print(f\"RADIO data verification: {radio_matched} songs with non-zero rank\")\n",
    "\n",
    "# 2. Streaming data\n",
    "print(\"\\nProcessing STREAMING data:\")\n",
    "for week in unified['week'].unique():\n",
    "    unified_week = unified[unified['week'] == week]\n",
    "    streaming_week = streaming_df[streaming_df['week'] == week]\n",
    "    \n",
    "    if streaming_week.empty:\n",
    "        print(f\"  Week {week}: No streaming data\")\n",
    "        continue\n",
    "    \n",
    "    matches = 0\n",
    "    for idx, hot_row in unified_week.iterrows():\n",
    "        match_row = find_match(hot_row, streaming_week)\n",
    "        \n",
    "        if match_row is not None:\n",
    "            # Copy rank\n",
    "            unified.loc[idx, 'streaming_rank'] = match_row['rank']\n",
    "            \n",
    "            # Copy other metrics\n",
    "            unified.loc[idx, 'streaming_last_week'] = match_row['str_last_week']\n",
    "            unified.loc[idx, 'streaming_peak'] = match_row['str_peak']\n",
    "            unified.loc[idx, 'streaming_woc'] = match_row['str_woc']\n",
    "            \n",
    "            # Copy label if available\n",
    "            if 'label' in match_row and pd.notnull(match_row['label']) and match_row['label'] != '':\n",
    "                if pd.isnull(unified.loc[idx, 'label']) or unified.loc[idx, 'label'] == '':\n",
    "                    unified.loc[idx, 'label'] = match_row['label']\n",
    "            \n",
    "            matches += 1\n",
    "    \n",
    "    print(f\"  Week {week}: Matched {matches} of {len(unified_week)} songs\")\n",
    "\n",
    "# Print verification\n",
    "streaming_matched = (unified['streaming_rank'] > 0).sum()\n",
    "print(f\"STREAMING data verification: {streaming_matched} songs with non-zero rank\")\n",
    "\n",
    "# 3. Sales data\n",
    "print(\"\\nProcessing SALES data:\")\n",
    "for week in unified['week'].unique():\n",
    "    unified_week = unified[unified['week'] == week]\n",
    "    sales_week = sales_df[sales_df['week'] == week]\n",
    "    \n",
    "    if sales_week.empty:\n",
    "        print(f\"  Week {week}: No sales data\")\n",
    "        continue\n",
    "    \n",
    "    matches = 0\n",
    "    for idx, hot_row in unified_week.iterrows():\n",
    "        match_row = find_match(hot_row, sales_week)\n",
    "        \n",
    "        if match_row is not None:\n",
    "            # Copy rank\n",
    "            unified.loc[idx, 'sales_rank'] = match_row['rank']\n",
    "            \n",
    "            # Copy other metrics\n",
    "            unified.loc[idx, 'sales_last_week'] = match_row['sales_last_week']\n",
    "            unified.loc[idx, 'sales_peak'] = match_row['sales_peak']\n",
    "            unified.loc[idx, 'sales_woc'] = match_row['sales_woc']\n",
    "            \n",
    "            # Copy label if available\n",
    "            if 'label' in match_row and pd.notnull(match_row['label']) and match_row['label'] != '':\n",
    "                if pd.isnull(unified.loc[idx, 'label']) or unified.loc[idx, 'label'] == '':\n",
    "                    unified.loc[idx, 'label'] = match_row['label']\n",
    "            \n",
    "            matches += 1\n",
    "    \n",
    "    print(f\"  Week {week}: Matched {matches} of {len(unified_week)} songs\")\n",
    "\n",
    "# Print verification\n",
    "sales_matched = (unified['sales_rank'] > 0).sum()\n",
    "print(f\"SALES data verification: {sales_matched} songs with non-zero rank\")\n",
    "\n",
    "# 4. Apple data\n",
    "print(\"\\nProcessing APPLE data:\")\n",
    "for week in unified['week'].unique():\n",
    "    unified_week = unified[unified['week'] == week]\n",
    "    apple_week = apple_df[apple_df['week'] == week]\n",
    "    \n",
    "    if apple_week.empty:\n",
    "        print(f\"  Week {week}: No Apple data\")\n",
    "        continue\n",
    "    \n",
    "    matches = 0\n",
    "    for idx, hot_row in unified_week.iterrows():\n",
    "        match_row = find_match(hot_row, apple_week)\n",
    "        \n",
    "        if match_row is not None:\n",
    "            # Copy rank\n",
    "            unified.loc[idx, 'apple_rank'] = match_row['rank']\n",
    "            \n",
    "            # Copy other metrics\n",
    "            unified.loc[idx, 'apple_last_week'] = match_row['am_last_week']\n",
    "            unified.loc[idx, 'apple_peak'] = match_row['am_peak']\n",
    "            unified.loc[idx, 'apple_woc'] = match_row['am_woc']\n",
    "            \n",
    "            # Copy label if available\n",
    "            if 'label' in match_row and pd.notnull(match_row['label']) and match_row['label'] != '':\n",
    "                if pd.isnull(unified.loc[idx, 'label']) or unified.loc[idx, 'label'] == '':\n",
    "                    unified.loc[idx, 'label'] = match_row['label']\n",
    "            \n",
    "            matches += 1\n",
    "    \n",
    "    print(f\"  Week {week}: Matched {matches} of {len(unified_week)} songs\")\n",
    "\n",
    "# Print verification\n",
    "apple_matched = (unified['apple_rank'] > 0).sum()\n",
    "print(f\"APPLE data verification: {apple_matched} songs with non-zero rank\")\n",
    "\n",
    "# 5. Spotify data\n",
    "print(\"\\nProcessing SPOTIFY data:\")\n",
    "for week in unified['week'].unique():\n",
    "    unified_week = unified[unified['week'] == week]\n",
    "    spotify_week = spotify_df[spotify_df['week'] == week]\n",
    "    \n",
    "    if spotify_week.empty:\n",
    "        print(f\"  Week {week}: No Spotify data\")\n",
    "        continue\n",
    "    \n",
    "    matches = 0\n",
    "    for idx, hot_row in unified_week.iterrows():\n",
    "        match_row = find_match(hot_row, spotify_week)\n",
    "        \n",
    "        if match_row is not None:\n",
    "            # Copy rank\n",
    "            unified.loc[idx, 'spotify_rank'] = match_row['rank']\n",
    "            \n",
    "            # Copy other metrics\n",
    "            unified.loc[idx, 'spotify_last_week'] = match_row['sp_last_week']\n",
    "            unified.loc[idx, 'spotify_peak'] = match_row['sp_peak']\n",
    "            unified.loc[idx, 'spotify_woc'] = match_row['sp_woc']\n",
    "            unified.loc[idx, 'spotify_streams'] = match_row['streams']\n",
    "            \n",
    "            # Copy label if available\n",
    "            if 'label' in match_row and pd.notnull(match_row['label']) and match_row['label'] != '':\n",
    "                if pd.isnull(unified.loc[idx, 'label']) or unified.loc[idx, 'label'] == '':\n",
    "                    unified.loc[idx, 'label'] = match_row['label']\n",
    "            \n",
    "            matches += 1\n",
    "    \n",
    "    print(f\"  Week {week}: Matched {matches} of {len(unified_week)} songs\")\n",
    "\n",
    "# Print verification\n",
    "spotify_matched = (unified['spotify_rank'] > 0).sum()\n",
    "print(f\"SPOTIFY data verification: {spotify_matched} songs with non-zero rank\")\n",
    "\n",
    "# Final verification\n",
    "print(\"\\nFINAL VERIFICATION:\")\n",
    "print(f\"Total rows: {len(unified)}\")\n",
    "print(f\"Hot100 songs: {(unified['hot100_rank'] > 0).sum()}\")\n",
    "print(f\"Radio songs: {(unified['radio_rank'] > 0).sum()}\")\n",
    "print(f\"Streaming songs: {(unified['streaming_rank'] > 0).sum()}\")\n",
    "print(f\"Sales songs: {(unified['sales_rank'] > 0).sum()}\")\n",
    "print(f\"Apple songs: {(unified['apple_rank'] > 0).sum()}\")\n",
    "print(f\"Spotify songs: {(unified['spotify_rank'] > 0).sum()}\")\n",
    "\n",
    "# Strategic label filling - after matching but before feature generation\n",
    "print(\"\\nPerforming strategic label filling...\")\n",
    "\n",
    "# 1. First pass: Fill labels based on the same song appearing in different weeks\n",
    "print(\"Step 1: Filling labels based on temporal data...\")\n",
    "# Group by track and artist\n",
    "song_groups = unified.groupby(['track_clean', 'artist_clean'])\n",
    "\n",
    "temporal_filled = 0\n",
    "for (track, artist), group in song_groups:\n",
    "    # Check if this song has a label in at least one week\n",
    "    labels = group['label'].dropna().unique()\n",
    "    labels = [l for l in labels if l and l != 'Unknown']\n",
    "    \n",
    "    if len(labels) > 0:\n",
    "        # Use the first non-empty label\n",
    "        valid_label = labels[0]\n",
    "        \n",
    "        # Apply this label to all weeks where this song appears but has no label\n",
    "        for idx in group.index:\n",
    "            if pd.isna(unified.loc[idx, 'label']) or unified.loc[idx, 'label'] == '' or unified.loc[idx, 'label'] == 'Unknown':\n",
    "                unified.loc[idx, 'label'] = valid_label\n",
    "                temporal_filled += 1\n",
    "\n",
    "print(f\"Filled {temporal_filled} labels using temporal matching\")\n",
    "\n",
    "# 2. Second pass: Use artist's most common label\n",
    "print(\"Step 2: Filling labels based on artist's common label...\")\n",
    "artist_labels = {}\n",
    "for idx, row in unified.iterrows():\n",
    "    if pd.notna(row['label']) and row['label'] != '' and row['label'] != 'Unknown':\n",
    "        artist_clean = row['artist_clean']\n",
    "        if artist_clean not in artist_labels:\n",
    "            artist_labels[artist_clean] = []\n",
    "        \n",
    "        artist_labels[artist_clean].append(row['label'])\n",
    "\n",
    "# Find most common label for each artist\n",
    "artist_most_common_label = {}\n",
    "for artist, labels in artist_labels.items():\n",
    "    if not labels:\n",
    "        continue\n",
    "    \n",
    "    label_counts = {}\n",
    "    for label in labels:\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    \n",
    "    most_common = max(label_counts.items(), key=lambda x: x[1])\n",
    "    artist_most_common_label[artist] = most_common[0]\n",
    "\n",
    "# Apply artist's most common label to songs missing labels\n",
    "artist_filled = 0\n",
    "for idx, row in unified.iterrows():\n",
    "    if pd.isna(row['label']) or row['label'] == '' or row['label'] == 'Unknown':\n",
    "        if row['artist_clean'] in artist_most_common_label:\n",
    "            unified.loc[idx, 'label'] = artist_most_common_label[row['artist_clean']]\n",
    "            artist_filled += 1\n",
    "\n",
    "print(f\"Filled {artist_filled} labels using artist's common label\")\n",
    "\n",
    "# 3. Third pass: Fill any remaining empty labels with 'Unknown'\n",
    "empty_before = (unified['label'].isna() | (unified['label'] == '')).sum()\n",
    "unified['label'] = unified['label'].fillna('Unknown')\n",
    "unified.loc[unified['label'] == '', 'label'] = 'Unknown'\n",
    "empty_after = (unified['label'].isna() | (unified['label'] == '')).sum()\n",
    "\n",
    "print(f\"Filled {empty_before - empty_after} remaining empty labels with 'Unknown'\")\n",
    "print(f\"Songs with known labels: {(unified['label'] != 'Unknown').sum()} of {len(unified)}\")\n",
    "\n",
    "# Add derived features and clean the data\n",
    "print(\"\\nAdding derived features...\")\n",
    "# Calculated columns for each platform\n",
    "platforms = {\n",
    "    'hot100': 100,\n",
    "    'radio': 50,\n",
    "    'streaming': 50,\n",
    "    'sales': 25,\n",
    "    'apple': 100,\n",
    "    'spotify': 200\n",
    "}\n",
    "\n",
    "# 1. Is collaboration\n",
    "unified['is_collab'] = unified['artist'].str.contains(\n",
    "    r'featuring|feat\\.|ft\\.|&|,|with|and', case=False, regex=True).astype(int)\n",
    "\n",
    "# 2. Calculate changes for each platform\n",
    "print(\"Calculating platform changes...\")\n",
    "for platform, size in platforms.items():\n",
    "    rank_col = f'{platform}_rank'\n",
    "    last_week_col = f'{platform}_last_week'\n",
    "    change_col = f'{platform}_change'\n",
    "    \n",
    "    # Make sure all these columns exist \n",
    "    if rank_col in unified.columns and last_week_col in unified.columns and change_col in unified.columns:\n",
    "        print(f\"  Calculating {change_col}\")\n",
    "        \n",
    "        # Both weeks on chart\n",
    "        mask = (unified[rank_col] > 0) & (unified[last_week_col] > 0)\n",
    "        unified.loc[mask, change_col] = ((unified.loc[mask, last_week_col] - \n",
    "                                        unified.loc[mask, rank_col]) / size * 100).round(2)\n",
    "        \n",
    "        # New entries\n",
    "        mask = (unified[rank_col] > 0) & (unified[last_week_col] == 0)\n",
    "        unified.loc[mask, change_col] = ((size + 1 - unified.loc[mask, rank_col]) / size * 100).round(2)\n",
    "        \n",
    "        # Dropped off\n",
    "        mask = (unified[rank_col] == 0) & (unified[last_week_col] > 0)\n",
    "        unified.loc[mask, change_col] = ((unified.loc[mask, last_week_col] - \n",
    "                                        (size + 1)) / size * 100).round(2)\n",
    "    else:\n",
    "        print(f\"  Missing columns for {platform} change calculation\")\n",
    "\n",
    "# 3. Calculate platforms available\n",
    "print(\"Calculating available platforms...\")\n",
    "rank_cols = [f'{platform}_rank' for platform in platforms.keys() if f'{platform}_rank' in unified.columns]\n",
    "unified['available_platforms'] = unified[rank_cols].apply(lambda row: (row > 0).sum(), axis=1)\n",
    "\n",
    "# 4. Determine best platform\n",
    "print(\"Determining best platform...\")\n",
    "unified['best_platform'] = ''\n",
    "for idx, row in unified.iterrows():\n",
    "    if row['available_platforms'] >= 1:\n",
    "        best_pos = float('inf')\n",
    "        best_platform = ''\n",
    "        \n",
    "        for platform, size in platforms.items():\n",
    "            rank_col = f'{platform}_rank'\n",
    "            if rank_col in unified.columns:\n",
    "                rank = row[rank_col]\n",
    "                if rank > 0 and rank < best_pos:\n",
    "                    best_pos = rank\n",
    "                    best_platform = platform\n",
    "        \n",
    "        unified.at[idx, 'best_platform'] = best_platform\n",
    "\n",
    "# 5. Calculate overall momentum\n",
    "print(\"Calculating platform momentum...\")\n",
    "change_cols = [f'{platform}_change' for platform in platforms.keys() if f'{platform}_change' in unified.columns]\n",
    "if change_cols:\n",
    "    unified['platform_momentum'] = unified[change_cols].replace(0, np.nan).mean(axis=1, skipna=True).round(2)\n",
    "    unified['platform_momentum'] = unified['platform_momentum'].fillna(0)\n",
    "else:\n",
    "    unified['platform_momentum'] = 0.0\n",
    "    print(\"  Warning: No change columns found for momentum calculation\")\n",
    "\n",
    "# Clean data\n",
    "print(\"\\nCleaning data...\")\n",
    "# Ensure numeric columns have correct data types\n",
    "for platform in platforms.keys():\n",
    "    # Rank columns\n",
    "    rank_col = f'{platform}_rank'\n",
    "    if rank_col in unified.columns:\n",
    "        unified[rank_col] = pd.to_numeric(unified[rank_col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Last week columns\n",
    "    last_week_col = f'{platform}_last_week'\n",
    "    if last_week_col in unified.columns:\n",
    "        unified[last_week_col] = pd.to_numeric(unified[last_week_col], errors='coerce').fillna(0).astype(int)\n",
    "        unified[last_week_col] = unified[last_week_col].replace(-1, 0)\n",
    "    \n",
    "    # Peak columns\n",
    "    peak_col = f'{platform}_peak'\n",
    "    if peak_col in unified.columns:\n",
    "        unified[peak_col] = pd.to_numeric(unified[peak_col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # WOC columns\n",
    "    woc_col = f'{platform}_woc'\n",
    "    if woc_col in unified.columns:\n",
    "        unified[woc_col] = pd.to_numeric(unified[woc_col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Change columns\n",
    "    change_col = f'{platform}_change'\n",
    "    if change_col in unified.columns:\n",
    "        unified[change_col] = pd.to_numeric(unified[change_col], errors='coerce').fillna(0)\n",
    "\n",
    "# Spotify streams\n",
    "if 'spotify_streams' in unified.columns:\n",
    "    unified['spotify_streams'] = pd.to_numeric(unified['spotify_streams'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Add advanced features\n",
    "print(\"\\nAdding advanced features...\")\n",
    "final_df = unified.copy()\n",
    "\n",
    "# 1. Platform comparisons\n",
    "final_df['apple_vs_spotify'] = 0.0\n",
    "final_df['radio_vs_streaming'] = 0.0\n",
    "final_df['streaming_vs_sales'] = 0.0\n",
    "\n",
    "# Apple vs Spotify\n",
    "if 'apple_rank' in final_df.columns and 'spotify_rank' in final_df.columns:\n",
    "    mask = (final_df['apple_rank'] > 0) & (final_df['spotify_rank'] > 0)\n",
    "    final_df.loc[mask, 'apple_vs_spotify'] = (\n",
    "        (final_df.loc[mask, 'spotify_rank'] / 200) - \n",
    "        (final_df.loc[mask, 'apple_rank'] / 100)\n",
    "    ).round(2)\n",
    "\n",
    "# Radio vs Streaming\n",
    "if 'radio_rank' in final_df.columns and 'streaming_rank' in final_df.columns:\n",
    "    mask = (final_df['radio_rank'] > 0) & (final_df['streaming_rank'] > 0)\n",
    "    final_df.loc[mask, 'radio_vs_streaming'] = (\n",
    "        (final_df.loc[mask, 'streaming_rank'] / 50) - \n",
    "        (final_df.loc[mask, 'radio_rank'] / 50)\n",
    "    ).round(2)\n",
    "\n",
    "# Streaming vs Sales\n",
    "if 'streaming_rank' in final_df.columns and 'sales_rank' in final_df.columns:\n",
    "    mask = (final_df['streaming_rank'] > 0) & (final_df['sales_rank'] > 0)\n",
    "    final_df.loc[mask, 'streaming_vs_sales'] = (\n",
    "        (final_df.loc[mask, 'sales_rank'] / 25) - \n",
    "        (final_df.loc[mask, 'streaming_rank'] / 50)\n",
    "    ).round(2)\n",
    "\n",
    "# 2. Top artists and labels by week\n",
    "final_df['is_top_artist'] = 0\n",
    "final_df['is_top_label'] = 0\n",
    "\n",
    "for week in final_df['week'].unique():\n",
    "    weekly_data = final_df[final_df['week'] == week]\n",
    "    \n",
    "    # TOP ARTISTS\n",
    "    artist_scores = {}\n",
    "    for artist in weekly_data['artist'].unique():\n",
    "        artist_data = weekly_data[weekly_data['artist'] == artist]\n",
    "        song_count = artist_data['track'].nunique()\n",
    "        avg_position = 101 - artist_data['hot100_rank'].mean()\n",
    "        best_rank = artist_data['hot100_rank'].min()\n",
    "        \n",
    "        score = song_count * 50 + avg_position * 0.5 + (101 - best_rank)\n",
    "        artist_scores[artist] = score\n",
    "    \n",
    "    top_artists = sorted(artist_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    for artist, _ in top_artists:\n",
    "        final_df.loc[(final_df['week'] == week) & (final_df['artist'] == artist), 'is_top_artist'] = 1\n",
    "    \n",
    "    # TOP LABELS\n",
    "    if 'label' in final_df.columns:\n",
    "        label_scores = {}\n",
    "        for label in weekly_data['label'].unique():\n",
    "            if pd.isna(label) or label == '' or label == 'Unknown':\n",
    "                continue\n",
    "            \n",
    "            label_data = weekly_data[weekly_data['label'] == label]\n",
    "            song_count = label_data['track'].nunique()\n",
    "            avg_position = 101 - label_data['hot100_rank'].mean()\n",
    "            top10_count = label_data[label_data['hot100_rank'] <= 10].shape[0]\n",
    "            \n",
    "            score = song_count * 30 + avg_position + top10_count * 20\n",
    "            label_scores[label] = score\n",
    "        \n",
    "        top_labels = sorted(label_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        for label, _ in top_labels:\n",
    "            final_df.loc[(final_df['week'] == week) & (final_df['label'] == label), 'is_top_label'] = 1\n",
    "\n",
    "# Clean up temporary columns\n",
    "final_df = final_df.drop(columns=['track_clean', 'artist_clean'])\n",
    "\n",
    "# Rearrange columns in the specified order\n",
    "print(\"\\nRearranging columns...\")\n",
    "\n",
    "# Define the column order\n",
    "column_order = [\n",
    "    # First group: quarter, month, week\n",
    "    'quarter', 'month', 'week',\n",
    "    \n",
    "    # Second group: track, artist, label\n",
    "    'track', 'artist', 'label',\n",
    "    \n",
    "    # Third group: all hot100 columns\n",
    "    'hot100_rank', 'hot100_last_week', 'hot100_peak', 'hot100_woc', 'hot100_change',\n",
    "]\n",
    "\n",
    "# Add all remaining columns that aren't explicitly listed above\n",
    "remaining_columns = [col for col in final_df.columns if col not in column_order]\n",
    "column_order.extend(remaining_columns)\n",
    "\n",
    "# Reorder the columns\n",
    "final_df = final_df[column_order]\n",
    "\n",
    "# Save the final dataset\n",
    "print(\"\\nSaving final dataset...\")\n",
    "final_df.to_csv(base_path + \"charts_final_enhanced.csv\", index=False)\n",
    "print(\"Final dataset saved successfully!\")\n",
    "\n",
    "# Final verification\n",
    "print(\"\\nFINAL VERIFICATION OF ENHANCED DATASET:\")\n",
    "print(f\"Total rows: {len(final_df)}\")\n",
    "print(f\"Hot100 songs: {(final_df['hot100_rank'] > 0).sum()}\")\n",
    "print(f\"Radio songs: {(final_df['radio_rank'] > 0).sum()}\")\n",
    "print(f\"Streaming songs: {(final_df['streaming_rank'] > 0).sum()}\")\n",
    "print(f\"Sales songs: {(final_df['sales_rank'] > 0).sum()}\")\n",
    "print(f\"Apple songs: {(final_df['apple_rank'] > 0).sum()}\")\n",
    "print(f\"Spotify songs: {(final_df['spotify_rank'] > 0).sum()}\")\n",
    "print(f\"Songs with known labels: {(final_df['label'] != 'Unknown').sum()} of {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8230a80c-6616-44e3-8402-795e038b2b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating advanced features...\n",
      "Adding seasonal variables...\n",
      "Converting change variables to decimal format...\n",
      "Calculating growth rate...\n",
      "Calculating acceleration...\n",
      "Calculating divergence index...\n",
      "Calculating platform momentum metrics...\n",
      "Recalculating platform comparisons in consistent order...\n",
      "Calculating lead-lag indicators...\n",
      "Reorganizing columns...\n",
      "Final dataset saved to final.csv\n",
      "Advanced feature generation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Script for generating advanced features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"charts_final_enhanced.csv\")\n",
    "print(\"Generating advanced features...\")\n",
    "\n",
    "# Platform list\n",
    "platforms = ['hot100', 'radio', 'streaming', 'sales', 'apple', 'spotify']\n",
    "\n",
    "# 1. Seasonal variables\n",
    "print(\"Adding seasonal variables...\")\n",
    "df['is_holiday_season'] = ((df['week'] >= 47) | (df['week'] == 1)).astype(int)\n",
    "df['is_summer_season'] = ((df['month'] >= 6) & (df['month'] <= 8)).astype(int)\n",
    "df['is_award_season'] = ((df['month'] == 2) | (df['month'] == 9) | (df['month'] == 10)).astype(int)\n",
    "\n",
    "# First convert all change variables to decimal format (0.30 instead of 30%)\n",
    "# We do this BEFORE calculating acceleration to ensure consistency\n",
    "print(\"Converting change variables to decimal format...\")\n",
    "change_cols = [col for col in df.columns if 'change' in col]\n",
    "for col in change_cols:\n",
    "    if df[col].abs().max() > 1:  # If values are large, they're likely percentages\n",
    "        df[col] = (df[col] / 100).round(2)\n",
    "\n",
    "# 2. Growth rate for each platform\n",
    "print(\"Calculating growth rate...\")\n",
    "for platform in platforms:\n",
    "    rank_col = f'{platform}_rank'\n",
    "    last_week_col = f'{platform}_last_week'\n",
    "    growth_col = f'{platform}_growth_rate'\n",
    "    \n",
    "    df[growth_col] = 0.0\n",
    "    \n",
    "    # Only calculate for tracks present in both weeks\n",
    "    mask = (df[rank_col] > 0) & (df[last_week_col] > 0)\n",
    "    \n",
    "    # Formula: (previous_position - current_position) / previous_position\n",
    "    df.loc[mask, growth_col] = (\n",
    "        (df.loc[mask, last_week_col] - df.loc[mask, rank_col]) / \n",
    "        df.loc[mask, last_week_col]\n",
    "    ).round(2)\n",
    "\n",
    "# 3. Acceleration for each platform - now calculated AFTER change conversion\n",
    "print(\"Calculating acceleration...\")\n",
    "for platform in platforms:\n",
    "    change_col = f'{platform}_change'\n",
    "    accel_col = f'{platform}_acceleration'\n",
    "    \n",
    "    # Group by track and calculate difference between consecutive changes\n",
    "    df[accel_col] = df.groupby(['track', 'artist'])[change_col].diff().fillna(0).round(2)\n",
    "\n",
    "# 4. Divergence index\n",
    "print(\"Calculating divergence index...\")\n",
    "normalized_ranks = []\n",
    "for platform in platforms:\n",
    "    rank_col = f'{platform}_rank'\n",
    "    \n",
    "    # Set chart size for normalization\n",
    "    if platform == 'hot100': max_rank = 100\n",
    "    elif platform in ['radio', 'streaming']: max_rank = 50\n",
    "    elif platform == 'sales': max_rank = 25\n",
    "    elif platform == 'apple': max_rank = 100\n",
    "    elif platform == 'spotify': max_rank = 200\n",
    "    else: continue\n",
    "    \n",
    "    # Normalize rank for valid positions\n",
    "    norm_col = f'{platform}_rank_norm'\n",
    "    df[norm_col] = 0.0\n",
    "    mask = df[rank_col] > 0\n",
    "    df.loc[mask, norm_col] = df.loc[mask, rank_col] / max_rank\n",
    "    normalized_ranks.append(norm_col)\n",
    "\n",
    "# Calculate divergence as standard deviation of normalized ranks\n",
    "if normalized_ranks:\n",
    "    df['platform_divergence'] = df[normalized_ranks].std(axis=1, skipna=True).round(2)\n",
    "    df['platform_divergence'] = df['platform_divergence'].fillna(0)\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    df = df.drop(columns=normalized_ranks)\n",
    "\n",
    "# 5. Calculate platform momentum metrics with proper naming\n",
    "print(\"Calculating platform momentum metrics...\")\n",
    "\n",
    "# Change momentum (renaming from platform_momentum)\n",
    "change_cols = [f'{platform}_change' for platform in platforms if f'{platform}_change' in df.columns]\n",
    "if change_cols:\n",
    "    # If platform_momentum already exists, rename it\n",
    "    if 'platform_momentum' in df.columns:\n",
    "        df['platform_change_momentum'] = df['platform_momentum']\n",
    "        df = df.drop(columns=['platform_momentum'])\n",
    "    else:\n",
    "        # Calculate platform_change_momentum\n",
    "        df['platform_change_momentum'] = df[change_cols].replace(0, np.nan).mean(axis=1, skipna=True).round(2)\n",
    "        df['platform_change_momentum'] = df['platform_change_momentum'].fillna(0)\n",
    "\n",
    "# Acceleration momentum\n",
    "accel_cols = [f'{platform}_acceleration' for platform in platforms if f'{platform}_acceleration' in df.columns]\n",
    "if accel_cols:\n",
    "    df['platform_acceleration_momentum'] = df[accel_cols].replace(0, np.nan).mean(axis=1, skipna=True).round(2)\n",
    "    df['platform_acceleration_momentum'] = df['platform_acceleration_momentum'].fillna(0)\n",
    "\n",
    "# 6. Recalculate comparison columns in consistent order\n",
    "print(\"Recalculating platform comparisons in consistent order...\")\n",
    "\n",
    "# Remove old comparison columns if they exist\n",
    "old_comparison_cols = ['apple_vs_spotify', 'radio_vs_streaming', 'streaming_vs_sales']\n",
    "for col in old_comparison_cols:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "# Calculate new comparison columns in consistent order\n",
    "# Spotify vs Apple\n",
    "if 'spotify_rank' in df.columns and 'apple_rank' in df.columns:\n",
    "    mask = (df['spotify_rank'] > 0) & (df['apple_rank'] > 0)\n",
    "    df['spotify_vs_apple'] = 0.0\n",
    "    df.loc[mask, 'spotify_vs_apple'] = (\n",
    "        (df.loc[mask, 'apple_rank'] / 100) - \n",
    "        (df.loc[mask, 'spotify_rank'] / 200)\n",
    "    ).round(2)\n",
    "\n",
    "# Streaming vs Radio\n",
    "if 'streaming_rank' in df.columns and 'radio_rank' in df.columns:\n",
    "    mask = (df['streaming_rank'] > 0) & (df['radio_rank'] > 0)\n",
    "    df['streaming_vs_radio'] = 0.0\n",
    "    df.loc[mask, 'streaming_vs_radio'] = (\n",
    "        (df.loc[mask, 'radio_rank'] / 50) - \n",
    "        (df.loc[mask, 'streaming_rank'] / 50)\n",
    "    ).round(2)\n",
    "\n",
    "# Streaming vs Sales\n",
    "if 'streaming_rank' in df.columns and 'sales_rank' in df.columns:\n",
    "    mask = (df['streaming_rank'] > 0) & (df['sales_rank'] > 0)\n",
    "    df['streaming_vs_sales'] = 0.0\n",
    "    df.loc[mask, 'streaming_vs_sales'] = (\n",
    "        (df.loc[mask, 'sales_rank'] / 25) - \n",
    "        (df.loc[mask, 'streaming_rank'] / 50)\n",
    "    ).round(2)\n",
    "\n",
    "# Add Radio vs Sales\n",
    "if 'radio_rank' in df.columns and 'sales_rank' in df.columns:\n",
    "    mask = (df['radio_rank'] > 0) & (df['sales_rank'] > 0)\n",
    "    df['radio_vs_sales'] = 0.0\n",
    "    df.loc[mask, 'radio_vs_sales'] = (\n",
    "        (df.loc[mask, 'sales_rank'] / 25) - \n",
    "        (df.loc[mask, 'radio_rank'] / 50)\n",
    "    ).round(2)\n",
    "\n",
    "# 7. Lead-lag indicators with improved handling of edge cases\n",
    "print(\"Calculating lead-lag indicators...\")\n",
    "# Modified to remove hot100-related lead-lag indicators\n",
    "platform_pairs = [\n",
    "    ('spotify', 'apple'),\n",
    "    ('streaming', 'radio'),\n",
    "    ('streaming', 'sales'),\n",
    "    ('radio', 'sales')  # Added this pair\n",
    "]\n",
    "\n",
    "for p1, p2 in platform_pairs:\n",
    "    p1_change = f'{p1}_change'\n",
    "    p2_change = f'{p2}_change'\n",
    "    indicator_col = f'{p1}_leads_{p2}'\n",
    "    \n",
    "    # Initialize column\n",
    "    df[indicator_col] = 0.0\n",
    "    \n",
    "    # Calculate for each track separately\n",
    "    for (track, artist), group in df.groupby(['track', 'artist']):\n",
    "        if len(group) < 3:  # Need at least 3 weeks for meaningful correlation\n",
    "            continue\n",
    "        \n",
    "        # Get valid rows with non-zero changes\n",
    "        valid_group = group[(~group[p1_change].isna()) & (~group[p2_change].isna()) & \n",
    "                           (group[p1_change] != 0) & (group[p2_change] != 0)]\n",
    "        \n",
    "        if len(valid_group) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Calculate correlation between p1 change in current week and p2 change in next week\n",
    "        p1_current = valid_group[p1_change].values[:-1]\n",
    "        p2_next = valid_group[p2_change].values[1:]\n",
    "        \n",
    "        if len(p1_current) >= 2 and np.any(p1_current != 0) and np.any(p2_next != 0):\n",
    "            # Check for variation in the data to avoid division by zero\n",
    "            if np.std(p1_current) > 0 and np.std(p2_next) > 0:\n",
    "                try:\n",
    "                    correlation = np.corrcoef(p1_current, p2_next)[0, 1]\n",
    "                    if not np.isnan(correlation):\n",
    "                        df.loc[group.index, indicator_col] = round(correlation, 2)\n",
    "                except:\n",
    "                    # Skip if correlation calculation fails\n",
    "                    continue\n",
    "\n",
    "# Organize columns in the requested order\n",
    "print(\"Reorganizing columns...\")\n",
    "\n",
    "# Define column order groups\n",
    "base_cols = ['quarter', 'month', 'week', 'track', 'artist', 'label']\n",
    "\n",
    "hot100_cols = ['hot100_rank', 'hot100_last_week', 'hot100_peak', 'hot100_woc', \n",
    "               'hot100_change', 'hot100_growth_rate', 'hot100_acceleration']\n",
    "\n",
    "radio_cols = ['radio_rank', 'radio_last_week', 'radio_peak', 'radio_woc', \n",
    "              'radio_change', 'radio_growth_rate', 'radio_acceleration']\n",
    "\n",
    "streaming_cols = ['streaming_rank', 'streaming_last_week', 'streaming_peak', 'streaming_woc', \n",
    "                 'streaming_change', 'streaming_growth_rate', 'streaming_acceleration']\n",
    "\n",
    "sales_cols = ['sales_rank', 'sales_last_week', 'sales_peak', 'sales_woc', \n",
    "             'sales_change', 'sales_growth_rate', 'sales_acceleration']\n",
    "\n",
    "apple_cols = ['apple_rank', 'apple_last_week', 'apple_peak', 'apple_woc', \n",
    "             'apple_change', 'apple_growth_rate', 'apple_acceleration']\n",
    "\n",
    "spotify_cols = ['spotify_rank', 'spotify_last_week', 'spotify_peak', 'spotify_woc', \n",
    "               'spotify_change', 'spotify_growth_rate', 'spotify_acceleration', 'spotify_streams']\n",
    "\n",
    "additional_cols = ['is_collab', 'is_top_artist', 'is_top_label', \n",
    "                  'is_holiday_season', 'is_summer_season', 'is_award_season',\n",
    "                  'available_platforms', 'best_platform', 'platform_change_momentum', 'platform_acceleration_momentum',\n",
    "                  'platform_divergence']\n",
    "\n",
    "# Updated comparison cols to match lead-lag order\n",
    "comparison_cols = ['spotify_vs_apple', 'streaming_vs_radio', 'streaming_vs_sales', 'radio_vs_sales']\n",
    "\n",
    "leadlag_cols = ['spotify_leads_apple', 'streaming_leads_radio', 'streaming_leads_sales', 'radio_leads_sales']\n",
    "\n",
    "# Combine all column groups in the desired order\n",
    "all_cols = (base_cols + hot100_cols + radio_cols + streaming_cols + \n",
    "            sales_cols + apple_cols + spotify_cols + \n",
    "            additional_cols + comparison_cols + leadlag_cols)\n",
    "\n",
    "# Filter to only include columns that exist in the dataframe\n",
    "final_cols = [col for col in all_cols if col in df.columns]\n",
    "\n",
    "# Reorder the dataframe\n",
    "df = df[final_cols]\n",
    "\n",
    "# Save to final CSV\n",
    "output_path = \"final.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Final dataset saved to {output_path}\")\n",
    "\n",
    "print(\"Advanced feature generation completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72367958-e32b-4960-a38a-1998735c3160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
